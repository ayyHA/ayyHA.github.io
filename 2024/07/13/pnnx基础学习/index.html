

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="模型部署基础知识,pnnx初了解">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  <meta name="description" content="模型部署基础知识,pnnx初了解">
<meta property="og:type" content="article">
<meta property="og:title" content="pnnx基础学习">
<meta property="og:url" content="http://example.com/2024/07/13/pnnx%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="ayyHA&#39;s blog">
<meta property="og:description" content="模型部署基础知识,pnnx初了解">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s2.loli.net/2024/07/17/umnT5Uze1aRfql6.png">
<meta property="og:image" content="https://s2.loli.net/2024/07/17/BT85sEXMcSyNCU3.png">
<meta property="article:published_time" content="2024-07-13T07:17:08.000Z">
<meta property="article:modified_time" content="2024-07-16T22:42:44.513Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="pnnx">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://s2.loli.net/2024/07/17/umnT5Uze1aRfql6.png">
  
  <title>pnnx基础学习 - ayyHA&#39;s blog</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->

  
<link rel="stylesheet" href="/css/mouse.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.12","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":"9c7ed39aa5906acb06d9f9cb7df236ae","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>ayyHA</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="pnnx基础学习">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2024-07-13 15:17" pubdate>
        2024年7月13日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      5.4k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      17 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">pnnx基础学习</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：几秒前
                
              </p>
            
            <div class="markdown-body">
              <h2 id="什么是模型部署"><a class="markdownIt-Anchor" href="#什么是模型部署"></a> 什么是模型部署</h2>
<blockquote>
<p><strong>本部分参考OpenMMLab在知乎的博文进行编写</strong></p>
</blockquote>
<p>模型部署需要明确<strong>部署场景</strong>,<strong>部署方式</strong>(中心服务化还是本地终端部署),模型优化指标,如何提高吞吐和减少延迟</p>
<h3 id="部署场景"><a class="markdownIt-Anchor" href="#部署场景"></a> 部署场景</h3>
<ul>
<li><strong>中心服务器云端部署</strong>
<ul>
<li>用户通过API调用接口或网页访问</li>
</ul>
</li>
<li><strong>边缘部署</strong>
<ul>
<li>用于<strong>嵌入式设备</strong>,要将模型打包封装到SDK,集成到嵌入式设备,<strong>数据处理和模型推理要在终端设备上执行</strong>(功耗,别耗电;要小,不占地儿)</li>
</ul>
</li>
</ul>
<h3 id="部署方式"><a class="markdownIt-Anchor" href="#部署方式"></a> 部署方式</h3>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">SDK部署</th>
<th style="text-align:center">Service部署</th>
</tr>
</thead>
<tbody>
<tr>
<td>部署环境</td>
<td style="text-align:center">SDK引擎</td>
<td style="text-align:center">训练框架</td>
</tr>
<tr>
<td>模型语义转换</td>
<td style="text-align:center">需要进行前后处理和模型算子重实现</td>
<td style="text-align:center">一般框架内部负责语义转换</td>
</tr>
<tr>
<td>前后处理对齐算子</td>
<td style="text-align:center">训练和部署对应两套实现,需要进行算子数值对齐</td>
<td style="text-align:center">共用算子</td>
</tr>
<tr>
<td>计算优化</td>
<td style="text-align:center">挖掘芯片编译器的深度优化能力</td>
<td style="text-align:center">利用引擎已有的训练优化能力</td>
</tr>
</tbody>
</table>
<h3 id="部署核心优化指标"><a class="markdownIt-Anchor" href="#部署核心优化指标"></a> 部署核心优化指标</h3>
<p>合理把控：成本、功耗、性价比</p>
<ul>
<li>成本
<ul>
<li>芯片选型</li>
<li>算力需求挑芯片（如加个DSP增加定点算力）</li>
</ul>
</li>
<li>功耗
<ul>
<li>电池电池电池！！要用专用的优化的加速器单元如NPU以节省功耗</li>
</ul>
</li>
<li>性价比
<ul>
<li>云端追求多路的吞吐量优化需求</li>
<li>终端追求单路延迟需要；针对CV和NLP问题对精度的要求不一样，因此有芯片选型的问题：CV INT4/INT8；NLP FP16</li>
</ul>
</li>
</ul>
<h3 id="部署流程"><a class="markdownIt-Anchor" href="#部署流程"></a> 部署流程</h3>
<p>这里用的是商汤的SenseParrots来讲解部署流程，且以SDK部署为例</p>
<h4 id="模型转换"><a class="markdownIt-Anchor" href="#模型转换"></a> 模型转换</h4>
<p>转换模型以适配不同框架。主流以ONNX或Caffe为模型交换格式。</p>
<p>主要分为：</p>
<ul>
<li><strong>计算图生成</strong></li>
<li><strong>计算图优化（optional，如算子融合）</strong></li>
<li><strong>计算图转换</strong></li>
</ul>
<h5 id="计算图生成"><a class="markdownIt-Anchor" href="#计算图生成"></a> 计算图生成</h5>
<p>通过一次推理来记录，将模型翻译成静态的表达（转成静态图）。在模型推理时，框架会记录算子的详细信息，也包括入参出参，以及所属层次</p>
<h5 id="计算图优化"><a class="markdownIt-Anchor" href="#计算图优化"></a> 计算图优化</h5>
<p>去除冗余op，算子融合</p>
<h5 id="计算图转换"><a class="markdownIt-Anchor" href="#计算图转换"></a> 计算图转换</h5>
<p>分析静态计算图算子，转换到目标格式。支持多后端（啥意思？）</p>
<h4 id="模型量化压缩"><a class="markdownIt-Anchor" href="#模型量化压缩"></a> 模型量化压缩</h4>
<p>边缘部署要求<strong>模型小</strong>，<strong>吞吐率高</strong> -&gt; 蒸馏/剪枝/量化</p>
<p>量化：FP32压缩到INT8/INT4乃至INT1（？），比如压到INT8-&gt;上面说了终端设备芯片选型会弄个定点计算单元，可以低比特指令实现低精度算子</p>
<p>量化技术栈：</p>
<ul>
<li><strong>量化训练（Quantization Aware Training）</strong>:插入伪量化算子（模拟低精度运算），通过梯度下降来做微调，以使得得到精度符合预期的模型</li>
<li><strong>离线量化（Post Training Quantization）</strong>： 少量校准数据集（原始数据集中挑），获得网络的激活分布，用统计手段或优化浮点定点输出分布来获得量化参数</li>
</ul>
<p>平衡吞吐和精度是一个问题；结合推理引擎挖掘芯片的能力；</p>
<h4 id="模型打包封装sdk"><a class="markdownIt-Anchor" href="#模型打包封装sdk"></a> 模型打包封装SDK</h4>
<p>要做前后处理，相当于是流水线中的一个流水段，可能是许多模型的一部分</p>
<p>保护模型还要加密（没想过还有这个，不过也合理）</p>
<h2 id="pnnx"><a class="markdownIt-Anchor" href="#pnnx"></a> PNNX</h2>
<p><strong>PNNX: <u>P</u>yTorch <u>N</u>eural <u>N</u>etwork e<u>X</u>change</strong></p>
<p>模型部署新方式</p>
<p><mark>介绍补充</mark></p>
<h2 id="pnnx2ncnn运行resnet-50快速上手vulkan"><a class="markdownIt-Anchor" href="#pnnx2ncnn运行resnet-50快速上手vulkan"></a> pnnx2ncnn运行ResNet-50快速上手(vulkan)</h2>
<p>开始前请先确定自己的ncnn已编译安装完成</p>
<h3 id="搭建项目结构"><a class="markdownIt-Anchor" href="#搭建项目结构"></a> 搭建项目结构</h3>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs txt">.<br>|-- CMakeLists.txt<br>|-- bin<br>|-- build<br>|-- images<br>|   `-- cat.jpg<br>|-- src<br>|   `-- infer.cpp<br>|-- utils<br>|   `-- resnet50.py<br>`-- weight_param<br></code></pre></td></tr></table></figure>
<p>项目结构如上所示,其中:</p>
<ul>
<li><strong>CMakeLists.txt</strong>: 用于构建项目</li>
<li><strong>bin</strong>: 用于存储最终编译得到的可执行文件</li>
<li><strong>build</strong>: 用于项目构建,以便清理</li>
<li><strong>images</strong>: 存放用于进行推理效果检测的图片,图片大小需要为224x224,这里准备了一张小猫的图片</li>
<li><strong>src</strong>: 用于存放源文件</li>
<li><strong>utils</strong>: 用于存放python文件</li>
<li><strong>weight_param</strong>: 用于存放python文件导出的TorchScript文件和pnnx进行转换后的权重和计算图参数文件</li>
</ul>
<h3 id="获取pnnx"><a class="markdownIt-Anchor" href="#获取pnnx"></a> 获取pnnx</h3>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install pnnx<br></code></pre></td></tr></table></figure>
<div class="note note-info">
            <p>注: 此方法方便快捷,当然也可以<code>wget</code>对应的源文件进行编译</p>
          </div>
<h3 id="pytorch-resnet50转换为torchscipt"><a class="markdownIt-Anchor" href="#pytorch-resnet50转换为torchscipt"></a> PyTorch ResNet50转换为TorchScipt</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br><br><span class="hljs-comment"># 加载预训练好的ResNet-50</span><br>resnet = models.resnet50(pretrained=<span class="hljs-literal">True</span>)<br>resnet.<span class="hljs-built_in">eval</span>()<br><br><span class="hljs-comment"># 输入参数为[1,3,224,224]</span><br>ipt = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br><br>jit_model = torch.jit.trace(resnet, ipt)<br>jit_model.save(<span class="hljs-string">&#x27;../weight_param/resnet50.pth&#x27;</span>) <br></code></pre></td></tr></table></figure>
<p>在utils下运行<code>python resnet50.py</code>后,在weight_param文件夹下得到<code>resnet50.pth</code></p>
<h3 id="pnnx转torchscipt为ncnn"><a class="markdownIt-Anchor" href="#pnnx转torchscipt为ncnn"></a> pnnx转TorchScipt为ncnn</h3>
<p>在weight_param下运行<code>pnnx resnet50.pth [1,3,224,224]</code></p>
<div class="note note-info">
            <p>注: 在命令行中通过输入<code>pnnx</code>后运行,可以看到一些<code>Sample Usage</code>,里面有举例说明用法</p>
          </div>
<p>运行指令后可以在当前文件夹下得到多个<code>.bin</code>,<code>.param</code>文件</p>
<p><code>.bin</code>文件内部存储的是模型的权重;</p>
<p><code>.param</code>文件存储的是计算图的详细信息</p>
<h3 id="编写推理文件"><a class="markdownIt-Anchor" href="#编写推理文件"></a> 编写推理文件</h3>
<p>在开始编写推理文件前,需要看一下<strong>pnnx转ncnn</strong>中的<code>resnet50.ncnn.param</code>,我们需要从该文件内获取输入输出对应的blob:</p>
<p><img src="https://s2.loli.net/2024/07/17/umnT5Uze1aRfql6.png" srcset="/img/loading.gif" lazyload alt="resnet50.ncnn.param" /></p>
<p>推理文件:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;net.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;algorithm&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">if</span> defined(USE_NCNN_SIMPLEOCV)</span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&quot;simpleocv.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">else</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;opencv2/core/core.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">endif</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;vector&gt;</span></span><br><br><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">detect_resnet50</span><span class="hljs-params">(<span class="hljs-keyword">const</span> cv::Mat&amp; bgr, std::vector&lt;<span class="hljs-keyword">float</span>&gt;&amp; cls_scores)</span></span><br><span class="hljs-function"></span>&#123;<br>    ncnn::Net resnet50;<br><br>    resnet50.opt.use_vulkan_compute = <span class="hljs-literal">true</span>;<br><br>    <span class="hljs-comment">// 加载模型的计算图参数和权重</span><br>    <span class="hljs-keyword">if</span> (resnet50.<span class="hljs-built_in">load_param</span>(<span class="hljs-string">&quot;weight_param/resnet50.ncnn.param&quot;</span>))<br>        <span class="hljs-built_in">exit</span>(<span class="hljs-number">-1</span>);<br>    <span class="hljs-keyword">if</span> (resnet50.<span class="hljs-built_in">load_model</span>(<span class="hljs-string">&quot;weight_param/resnet50.ncnn.bin&quot;</span>))<br>        <span class="hljs-built_in">exit</span>(<span class="hljs-number">-1</span>);<br>	<span class="hljs-comment">// 图片格式转换 BGR-&gt;RGB</span><br>    ncnn::Mat in = ncnn::Mat::<span class="hljs-built_in">from_pixels_resize</span>(bgr.data, ncnn::Mat::PIXEL_BGR2RGB, bgr.cols, bgr.rows, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>);<br>    <br>    <span class="hljs-comment">// 图像归一化,这里做的是:(x/255 - 0.485) / 0.229 ,上下同时乘255可得</span><br>    <span class="hljs-comment">// (x - 0.485*255) / 0.229*255 ,而在substract_mean_normalize中的标准差是倒数</span><br>    <span class="hljs-comment">// 因此norm_vals的标准差取了倒数</span><br>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> mean_vals[<span class="hljs-number">3</span>] = &#123;<span class="hljs-number">0.485f</span>*<span class="hljs-number">255.f</span>, <span class="hljs-number">0.456f</span>*<span class="hljs-number">255.f</span>, <span class="hljs-number">0.406f</span>*<span class="hljs-number">255.f</span>&#125;;<br>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">float</span> norm_vals[<span class="hljs-number">3</span>] = &#123;<span class="hljs-number">1</span>/<span class="hljs-number">0.229f</span>/<span class="hljs-number">255.f</span>, <span class="hljs-number">1</span>/<span class="hljs-number">0.224f</span>/<span class="hljs-number">255.f</span>, <span class="hljs-number">1</span>/<span class="hljs-number">0.225f</span>/<span class="hljs-number">255.f</span>&#125;;<br>    in.<span class="hljs-built_in">substract_mean_normalize</span>(mean_vals, norm_vals);<br><br>    ncnn::Extractor ex = resnet50.<span class="hljs-built_in">create_extractor</span>();<br>	<br>    ex.<span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;in0&quot;</span>, in);<br><br>    ncnn::Mat out;<br>    ex.<span class="hljs-built_in">extract</span>(<span class="hljs-string">&quot;out0&quot;</span>, out);<br><br>    cls_scores.<span class="hljs-built_in">resize</span>(out.w);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; out.w; j++)<br>    &#123;<br>        cls_scores[j] = out[j];<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">print_topk</span><span class="hljs-params">(<span class="hljs-keyword">const</span> std::vector&lt;<span class="hljs-keyword">float</span>&gt;&amp; cls_scores, <span class="hljs-keyword">int</span> topk)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">// 前topk的局部排序</span><br>    <span class="hljs-keyword">int</span> size = cls_scores.<span class="hljs-built_in">size</span>();<br>    std::vector&lt;std::pair&lt;<span class="hljs-keyword">float</span>, <span class="hljs-keyword">int</span>&gt; &gt; vec;<br>    vec.<span class="hljs-built_in">resize</span>(size);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; size; i++)<br>    &#123;<br>        vec[i] = std::<span class="hljs-built_in">make_pair</span>(cls_scores[i], i);<br>    &#125;<br><br>    std::<span class="hljs-built_in">partial_sort</span>(vec.<span class="hljs-built_in">begin</span>(), vec.<span class="hljs-built_in">begin</span>() + topk, vec.<span class="hljs-built_in">end</span>(),<br>                      std::greater&lt;std::pair&lt;<span class="hljs-keyword">float</span>, <span class="hljs-keyword">int</span>&gt; &gt;());<br><br>    <span class="hljs-comment">// 打印topk及对应的分数</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; topk; i++)<br>    &#123;<br>        <span class="hljs-keyword">float</span> score = vec[i].first;<br>        <span class="hljs-keyword">int</span> index = vec[i].second;<br>        <span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;%d = %f\n&quot;</span>, index, score);<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span>** argv)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">if</span> (argc != <span class="hljs-number">2</span>)<br>    &#123;<br>        <span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;Usage: %s [imagepath]\n&quot;</span>, argv[<span class="hljs-number">0</span>]);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* imagepath = argv[<span class="hljs-number">1</span>];<br>	<br>    cv::Mat m = cv::<span class="hljs-built_in">imread</span>(imagepath, <span class="hljs-number">1</span>);<br>    <span class="hljs-keyword">if</span> (m.<span class="hljs-built_in">empty</span>())<br>    &#123;<br>        <span class="hljs-built_in">fprintf</span>(stderr, <span class="hljs-string">&quot;cv::imread %s failed\n&quot;</span>, imagepath);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125;<br><br>    std::vector&lt;<span class="hljs-keyword">float</span>&gt; cls_scores;<br>    <span class="hljs-built_in">detect_resnet50</span>(m, cls_scores);<br>	<br>    <span class="hljs-comment">// 打印得分前三的类别</span><br>    <span class="hljs-built_in">print_topk</span>(cls_scores, <span class="hljs-number">3</span>);<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>
<p>编写完推理文件后,进行CMakeLists.txt的编写:</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">project</span>(NCNN_DEMO)<br><span class="hljs-keyword">cmake_minimum_required</span>(VERSION <span class="hljs-number">2.8</span>.<span class="hljs-number">12</span>)<br><span class="hljs-keyword">set</span>(CMAKE_BUILD_TYPE Debug)<br><br><br><span class="hljs-keyword">set</span>(CMAKE_PREFIX_PATH <span class="hljs-variable">$&#123;CMAKE_PREFIX_PATH&#125;</span> <span class="hljs-string">&quot;/path/to/ncnn/build/install&quot;</span>)<br><span class="hljs-keyword">find_package</span>(ncnn   REQUIRED)<br><span class="hljs-keyword">find_package</span>(OpenCV REQUIRED)<br><br><br><span class="hljs-keyword">set</span>(CMAKE_RUNTIME_OUTPUT_DIRECTORY <span class="hljs-variable">$&#123;CMAKE_SOURCE_DIR&#125;</span>/bin)<br><br><span class="hljs-keyword">add_executable</span>(resnet50 src/infer.cpp)<br><span class="hljs-keyword">target_link_libraries</span>(resnet50 ncnn <span class="hljs-variable">$&#123;OpenCV_LIBS&#125;</span>)<br></code></pre></td></tr></table></figure>
<div class="note note-info">
            <p>注: 上面的<code>CMAKE_PREFIX_PATH</code>加上的搜索路径是你编译安装好ncnn后,build文件夹内的install文件夹</p>
          </div>
<h3 id="构建及测试"><a class="markdownIt-Anchor" href="#构建及测试"></a> 构建及测试</h3>
<p>进入build文件夹下,执行<code>cmake ..</code>构建项目,而后执行<code>make</code>以生成可执行文件</p>
<p><code>cd ..</code>退到项目根目录下</p>
<p>运行<code>./bin/resnet50 ./images/cat.jpg</code>以查看推理结果:</p>
<img src="https://s2.loli.net/2024/07/17/BT85sEXMcSyNCU3.png" srcset="/img/loading.gif" lazyload alt="pnnx2ncnn_infer" style="zoom:50%;" />
<p>这里输出的283,154一类的数字是训练用的标签,因为采用的ResNet-50是在ImageNet数据集上进行预训练的,其中上述标签对应具体类别为:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs txt">154: &#x27;Pekinese, Pekingese, Peke&#x27;, // 哈巴狗<br>283: &#x27;Persian cat&#x27;, // 波斯猫<br>284: &#x27;Siamese cat, Siamese&#x27;, // 暹罗猫<br></code></pre></td></tr></table></figure>
<p>可以看出来,它确实正确预测了是只猫(虽然具体的种类错了)</p>
<p><strong>参考文件:</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/367042545">AI 框架部署方案之模型部署概述</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/HuPengsheet/use-ncnn/blob/main/notes/ncnn02-onnx%E8%BD%ACncnn%E6%A8%A1%E5%9E%8B%E8%B7%91resnet18.md">onnx2ncnn</a></li>
</ul>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/pnnx/">pnnx</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', function() {
        var options = Object.assign(
          {"clientID":"1db059241d978c80eecd","clientSecret":"fa4f54290b2645c1dd4af84d9241dcb8c3e8e637","repo":"ayyBlog","owner":"ayyha","admin":["ayyha"],"language":"zh-CN","labels":["Gitalk"],"perPage":10,"pagerDirection":"last","distractionFreeMode":false,"createIssueManually":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token"},
          {
            id: '970d37484ea020826d1c9c04e337e3a7'
          }
        )
        var gitalk = new Gitalk(options);
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>




  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>





  

  
    <!-- KaTeX -->
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0/dist/katex.min.css" />
  








  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?9c7ed39aa5906acb06d9f9cb7df236ae";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>

  <script type="text/javascript" src="/js/funnyTitle.js"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/assets/hijiki.model.json"},"display":{"position":"left","width":150,"height":300,"hOffset":30,"vOffset":-50,"superSample":2},"mobile":{"show":false},"react":{"opacityDefault":0.7,"opacityOnHover":0.2}});</script></body>
</html>
